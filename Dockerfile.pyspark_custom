# Use the latest apache/spark image as the base
FROM apache/spark:latest

# Set user to root to avoid permission issues
USER root

# Update and install necessary tools
RUN apt-get update -q && apt-get install -y -q software-properties-common

# Add deadsnakes PPA to get newer versions of Python
RUN add-apt-repository -y ppa:deadsnakes/ppa && apt-get update -q

# Install Python 3.11
RUN apt-get install -y -q python3.11 python3.11-distutils python3.11-venv

# Set Python 3.11 as the default Python version
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1

# Install pip for Python 3.11
RUN curl https://bootstrap.pypa.io/get-pip.py | python3.11

# Copy requirements.txt and install required python packages
COPY requirements.txt /tmp/
RUN python3.11 -m pip install --no-cache-dir -r /tmp/requirements.txt

# Set the PYSPARK_PYTHON environment variable to ensure Spark uses Python 3.11
ENV PYSPARK_PYTHON=python3.11

# Return to the default user (optional)
USER ${SPARK_UID}
